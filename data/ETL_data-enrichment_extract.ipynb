{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Customer Data Enrichment - The Extract Component\n",
        "\n",
        "**Scenario**: This morning you cleaned customer data (Transform). Now we'll enhance it with external data sources (Extract) before loading it to our database (Load).\n",
        "\n",
        "**Business Need**: Your customer support team needs enriched customer profiles including:\n",
        "- Validated postcodes with area information\n",
        "- Company data for business customers  \n",
        "- Risk scoring based on location\n",
        "\n",
        "**Learning Objectives**:\n",
        "- Extract data from multiple APIs\n",
        "- Combine internal and external data sources\n",
        "- Handle API failures gracefully\n",
        "- Prepare data for database loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Your Cleaned Customer Data\n",
        "\n",
        "Start with the customer data you cleaned this morning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "# Load the cleaned customer data from this morning\n",
        "# (In real scenario, this would come from your morning output)\n",
        "customers_clean = {\n",
        "    'customer_id': [1001, 1002, 1003, 1004, 1005, 1006],\n",
        "    'first_name': ['John', 'Jane', 'Mike', 'Sarah', 'Bob', 'Alice'],\n",
        "    'last_name': ['Smith', 'Doe', 'Johnson', 'Wilson', 'Brown', 'Cooper'],\n",
        "    'email': ['john@email.com', 'jane@email.com', 'mike@techcorp.com', \n",
        "              'sarah@retailplus.com', 'bob@email.com', 'alice@freelance.com'],\n",
        "    'phone': ['01234567890', '01987654321', '01555123456', \n",
        "              '01777888999', '01111222333', '01444555666'],\n",
        "    'postcode': ['SW1A 1AA', 'M1 1AA', 'B1 1AA', 'LS1 1AA', 'NE1 1AA', 'CF10 1AA'],\n",
        "    'company': ['', '', 'TechCorp Ltd', 'Retail Plus', '', 'Freelance Design'],\n",
        "    'status': ['active', 'active', 'active', 'suspended', 'active', 'active']\n",
        "}\n",
        "\n",
        "df_customers = pd.DataFrame(customers_clean)\n",
        "print(\"=== CLEANED CUSTOMER DATA ===\")\n",
        "print(df_customers)\n",
        "print(f\"\\nTotal customers to enrich: {len(df_customers)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Postcode Enrichment - Geographic Data\n",
        "\n",
        "Use the UK Postcodes API to get detailed location information for risk assessment and regional analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enrich_postcode(postcode):\n",
        "    \"\"\"\n",
        "    Extract geographic data from UK Postcodes API\n",
        "    Returns: dict with area information or None if failed\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Clean postcode for API (remove spaces)\n",
        "        clean_postcode = postcode.replace(' ', '')\n",
        "        \n",
        "        # Call the free UK Postcodes API\n",
        "        url = f\"https://api.postcodes.io/postcodes/{clean_postcode}\"\n",
        "        response = requests.get(url, timeout=5)\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            result = data['result']\n",
        "            \n",
        "            return {\n",
        "                'region': result.get('region', 'Unknown'),\n",
        "                'country': result.get('country', 'Unknown'),\n",
        "                'district': result.get('admin_district', 'Unknown'),\n",
        "                'longitude': result.get('longitude', 0),\n",
        "                'latitude': result.get('latitude', 0)\n",
        "            }\n",
        "        else:\n",
        "            print(f\"⚠️  Postcode API failed for {postcode}: {response.status_code}\")\n",
        "            return None\n",
        "            \n",
        "    except requests.exceptions.Timeout:\n",
        "        print(f\"⚠️  Timeout for postcode {postcode}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Error processing {postcode}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Test the function with one postcode\n",
        "test_result = enrich_postcode('SW1A 1AA')\n",
        "print(\"=== POSTCODE API TEST ===\")\n",
        "print(f\"Test result: {test_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Apply Postcode Enrichment to All Customers\n",
        "\n",
        "Now let's extract geographic data for all customers. Notice how we handle API failures gracefully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize new columns for geographic data\n",
        "df_customers['region'] = 'Unknown'\n",
        "df_customers['country'] = 'Unknown' \n",
        "df_customers['district'] = 'Unknown'\n",
        "df_customers['longitude'] = 0.0\n",
        "df_customers['latitude'] = 0.0\n",
        "df_customers['geo_enriched'] = False\n",
        "\n",
        "print(\"=== ENRICHING POSTCODES ===\")\n",
        "successful_enrichments = 0\n",
        "\n",
        "for index, row in df_customers.iterrows():\n",
        "    postcode = row['postcode']\n",
        "    print(f\"Processing {postcode}...\")\n",
        "    \n",
        "    # Extract geographic data\n",
        "    geo_data = enrich_postcode(postcode)\n",
        "    \n",
        "    if geo_data:\n",
        "        # Update the dataframe with extracted data\n",
        "        df_customers.at[index, 'region'] = geo_data['region']\n",
        "        df_customers.at[index, 'country'] = geo_data['country']\n",
        "        df_customers.at[index, 'district'] = geo_data['district']\n",
        "        df_customers.at[index, 'longitude'] = geo_data['longitude']\n",
        "        df_customers.at[index, 'latitude'] = geo_data['latitude']\n",
        "        df_customers.at[index, 'geo_enriched'] = True\n",
        "        successful_enrichments += 1\n",
        "        print(f\"  ✅ Enriched: {geo_data['region']}, {geo_data['district']}\")\n",
        "    else:\n",
        "        print(f\"  ❌ Failed to enrich {postcode}\")\n",
        "    \n",
        "    # Be nice to the API - small delay between requests\n",
        "    time.sleep(0.5)\n",
        "\n",
        "print(f\"\\n=== ENRICHMENT SUMMARY ===\")\n",
        "print(f\"Successfully enriched: {successful_enrichments}/{len(df_customers)} postcodes\")\n",
        "print(f\"Success rate: {successful_enrichments/len(df_customers):.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Company Data Enrichment\n",
        "\n",
        "For business customers, let's enrich with company information. In a real scenario, you might use Companies House API or similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enrich_company_data(company_name, email_domain):\n",
        "    \"\"\"\n",
        "    Simulate company data enrichment\n",
        "    In reality, you'd call Companies House API, Clearbit, or similar\n",
        "    \"\"\"\n",
        "    # Simulate company database lookup\n",
        "    company_db = {\n",
        "        'techcorp.com': {\n",
        "            'company_size': 'Medium (50-250 employees)',\n",
        "            'industry': 'Technology',\n",
        "            'risk_score': 'Low',\n",
        "            'annual_revenue': '£2M-£10M'\n",
        "        },\n",
        "        'retailplus.com': {\n",
        "            'company_size': 'Large (250+ employees)', \n",
        "            'industry': 'Retail',\n",
        "            'risk_score': 'Medium',\n",
        "            'annual_revenue': '£10M+'\n",
        "        },\n",
        "        'freelance.com': {\n",
        "            'company_size': 'Micro (1-10 employees)',\n",
        "            'industry': 'Creative Services', \n",
        "            'risk_score': 'Medium',\n",
        "            'annual_revenue': '£0-£100K'\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Extract domain from email\n",
        "    if '@' in email_domain:\n",
        "        domain = email_domain.split('@')[1]\n",
        "    else:\n",
        "        domain = email_domain\n",
        "    \n",
        "    # Look up company data\n",
        "    if domain in company_db:\n",
        "        return company_db[domain]\n",
        "    else:\n",
        "        # Default for unknown companies\n",
        "        return {\n",
        "            'company_size': 'Unknown',\n",
        "            'industry': 'Unknown',\n",
        "            'risk_score': 'Unknown', \n",
        "            'annual_revenue': 'Unknown'\n",
        "        }\n",
        "\n",
        "# Add company enrichment columns\n",
        "df_customers['company_size'] = 'Individual'\n",
        "df_customers['industry'] = 'Personal'\n",
        "df_customers['risk_score'] = 'Low'\n",
        "df_customers['annual_revenue'] = 'N/A'\n",
        "df_customers['is_business'] = False\n",
        "\n",
        "print(\"=== ENRICHING COMPANY DATA ===\")\n",
        "\n",
        "for index, row in df_customers.iterrows():\n",
        "    # Check if customer has company information\n",
        "    if row['company'] and row['company'] != '':\n",
        "        print(f\"Processing business customer: {row['company']}\")\n",
        "        \n",
        "        # Extract company data\n",
        "        company_data = enrich_company_data(row['company'], row['email'])\n",
        "        \n",
        "        # Update dataframe\n",
        "        df_customers.at[index, 'company_size'] = company_data['company_size']\n",
        "        df_customers.at[index, 'industry'] = company_data['industry']\n",
        "        df_customers.at[index, 'risk_score'] = company_data['risk_score']\n",
        "        df_customers.at[index, 'annual_revenue'] = company_data['annual_revenue']\n",
        "        df_customers.at[index, 'is_business'] = True\n",
        "        \n",
        "        print(f\"  ✅ Industry: {company_data['industry']}, Size: {company_data['company_size']}\")\n",
        "    else:\n",
        "        print(f\"Individual customer: {row['first_name']} {row['last_name']}\")\n",
        "\n",
        "business_customers = df_customers['is_business'].sum()\n",
        "print(f\"\\n=== COMPANY ENRICHMENT SUMMARY ===\")\n",
        "print(f\"Business customers identified: {business_customers}\")\n",
        "print(f\"Individual customers: {len(df_customers) - business_customers}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Calculate Risk Scores\n",
        "\n",
        "Combine geographic and company data to create comprehensive customer risk profiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_customer_risk(row):\n",
        "    \"\"\"\n",
        "    Business logic: Calculate customer risk based on multiple factors\n",
        "    This is the Transform logic that combines extracted data\n",
        "    \"\"\"\n",
        "    risk_factors = []\n",
        "    risk_score = 0\n",
        "    \n",
        "    # Geographic risk (example business rules)\n",
        "    high_risk_regions = ['London', 'West Midlands']\n",
        "    if row['region'] in high_risk_regions:\n",
        "        risk_score += 2\n",
        "        risk_factors.append('High-risk region')\n",
        "    \n",
        "    # Company risk\n",
        "    if row['is_business']:\n",
        "        if row['company_size'] == 'Micro (1-10 employees)':\n",
        "            risk_score += 1\n",
        "            risk_factors.append('Small business')\n",
        "        elif row['annual_revenue'] == '£10M+':\n",
        "            risk_score -= 1  # Large companies are lower risk\n",
        "            risk_factors.append('Large company (low risk)')\n",
        "    \n",
        "    # Account status risk\n",
        "    if row['status'] == 'suspended':\n",
        "        risk_score += 3\n",
        "        risk_factors.append('Account suspended')\n",
        "    \n",
        "    # Data quality risk\n",
        "    if not row['geo_enriched']:\n",
        "        risk_score += 1\n",
        "        risk_factors.append('Incomplete geographic data')\n",
        "    \n",
        "    # Convert score to category\n",
        "    if risk_score <= 0:\n",
        "        risk_category = 'Low'\n",
        "    elif risk_score <= 2:\n",
        "        risk_category = 'Medium'\n",
        "    else:\n",
        "        risk_category = 'High'\n",
        "    \n",
        "    return risk_category, risk_score, '; '.join(risk_factors) if risk_factors else 'Standard profile'\n",
        "\n",
        "# Apply risk calculation\n",
        "print(\"=== CALCULATING CUSTOMER RISK SCORES ===\")\n",
        "\n",
        "risk_data = df_customers.apply(calculate_customer_risk, axis=1, result_type='expand')\n",
        "df_customers['calculated_risk'] = risk_data[0]\n",
        "df_customers['risk_score_numeric'] = risk_data[1] \n",
        "df_customers['risk_factors'] = risk_data[2]\n",
        "\n",
        "# Risk distribution analysis\n",
        "print(\"\\n=== RISK ANALYSIS SUMMARY ===\")\n",
        "risk_distribution = df_customers['calculated_risk'].value_counts()\n",
        "for risk_level, count in risk_distribution.items():\n",
        "    percentage = (count / len(df_customers)) * 100\n",
        "    print(f\"{risk_level} Risk: {count} customers ({percentage:.1f}%)\")\n",
        "\n",
        "print(\"\\n=== HIGH RISK CUSTOMERS ===\")\n",
        "high_risk = df_customers[df_customers['calculated_risk'] == 'High']\n",
        "if not high_risk.empty:\n",
        "    for _, customer in high_risk.iterrows():\n",
        "        print(f\"⚠️  {customer['first_name']} {customer['last_name']}: {customer['risk_factors']}\")\n",
        "else:\n",
        "    print(\"No high-risk customers identified\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Prepare for Database Loading\n",
        "\n",
        "Clean and structure the enriched data for loading into SQL Server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create final dataset for database loading\n",
        "df_final = df_customers.copy()\n",
        "\n",
        "# Add processing metadata\n",
        "df_final['processed_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "df_final['data_source'] = 'ETL_Pipeline_v1'\n",
        "df_final['enrichment_status'] = df_final.apply(\n",
        "    lambda row: 'Fully Enriched' if row['geo_enriched'] and row['is_business'] \n",
        "    else 'Partially Enriched' if row['geo_enriched'] or row['is_business']\n",
        "    else 'Basic Profile', axis=1\n",
        ")\n",
        "\n",
        "# Data validation before loading\n",
        "print(\"=== DATA VALIDATION FOR DATABASE LOADING ===\")\n",
        "\n",
        "# Check for required fields\n",
        "required_fields = ['customer_id', 'first_name', 'last_name', 'email']\n",
        "missing_data = df_final[required_fields].isnull().sum()\n",
        "print(\"Missing required data:\")\n",
        "for field, count in missing_data.items():\n",
        "    print(f\"  {field}: {count} missing values\")\n",
        "\n",
        "# Data quality metrics\n",
        "print(\"\\nData quality metrics:\")\n",
        "print(f\"  Total records: {len(df_final)}\")\n",
        "print(f\"  Geo-enriched: {df_final['geo_enriched'].sum()} ({df_final['geo_enriched'].mean():.1%})\")\n",
        "print(f\"  Business customers: {df_final['is_business'].sum()}\")\n",
        "print(f\"  High-risk customers: {(df_final['calculated_risk'] == 'High').sum()}\")\n",
        "\n",
        "# Show final enriched dataset\n",
        "print(\"\\n=== FINAL ENRICHED CUSTOMER DATA ===\")\n",
        "# Display key columns only for readability\n",
        "display_columns = ['customer_id', 'first_name', 'last_name', 'region', 'industry', \n",
        "                  'calculated_risk', 'enrichment_status']\n",
        "print(df_final[display_columns])\n",
        "\n",
        "print(f\"\\n✅ Ready for database loading: {len(df_final)} enriched customer records\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Save Enriched Data\n",
        "\n",
        "Export the enriched dataset for the Load phase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save enriched data for database loading\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "output_file = f'enriched_customers_{timestamp}.csv'\n",
        "\n",
        "df_final.to_csv(output_file, index=False)\n",
        "print(f\"💾 Enriched data saved to: {output_file}\")\n",
        "\n",
        "# Create summary report for stakeholders\n",
        "summary_report = f\"\"\"\n",
        "CUSTOMER DATA ENRICHMENT REPORT\n",
        "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "================================\n",
        "\n",
        "INPUT DATA:\n",
        "- Source records: {len(df_customers)}\n",
        "- Clean customer data from morning transformation\n",
        "\n",
        "ENRICHMENT SOURCES:\n",
        "- UK Postcodes API (geographic data)\n",
        "- Company database (business information)\n",
        "- Risk calculation engine (custom business logic)\n",
        "\n",
        "OUTPUT DATA:\n",
        "- Total enriched records: {len(df_final)}\n",
        "- Geographic enrichment: {df_final['geo_enriched'].sum()}/{len(df_final)} ({df_final['geo_enriched'].mean():.1%})\n",
        "- Business customers identified: {df_final['is_business'].sum()}\n",
        "- High-risk customers: {(df_final['calculated_risk'] == 'High').sum()}\n",
        "\n",
        "BUSINESS VALUE:\n",
        "- Customer support agents now have geographic context\n",
        "- Business customers identified for B2B processes  \n",
        "- Risk scores enable proactive account management\n",
        "- Complete customer 360-degree view ready for CRM\n",
        "\n",
        "NEXT STEPS:\n",
        "- Load enriched data to customer database\n",
        "- Update CRM system with risk scores\n",
        "- Configure alerts for high-risk customers\n",
        "\"\"\"\n",
        "\n",
        "summary_file = f'enrichment_summary_{timestamp}.txt'\n",
        "with open(summary_file, 'w') as f:\n",
        "    f.write(summary_report)\n",
        "\n",
        "print(f\"📊 Summary report saved to: {summary_file}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"🎉 EXTRACT PHASE COMPLETE!\")\n",
        "print(\"=\"*50)\n",
        "print(\"You've successfully:\")\n",
        "print(\"✅ Extracted data from multiple APIs\")\n",
        "print(\"✅ Combined internal and external data sources\")\n",
        "print(\"✅ Applied business logic and risk assessment\")\n",
        "print(\"✅ Prepared data for database loading\")\n",
        "print(\"\\nNext: Load this enriched data into SQL Server (Load phase)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection Questions\n",
        "\n",
        "**Technical Learning:**\n",
        "1. How did you handle API failures? What other strategies could you use?\n",
        "2. What challenges did you face combining data from different sources?\n",
        "3. How would you modify this pipeline for 100,000 customers?\n",
        "\n",
        "**Business Application:**\n",
        "4. What external data sources would benefit your organisation?\n",
        "5. How would you explain the value of data enrichment to your manager?\n",
        "6. What data quality issues might arise in production?\n",
        "\n",
        "**ETL Concepts:**\n",
        "7. How does this Extract phase connect to this morning's Transform work?\n",
        "8. What preparation is needed for the Load phase?\n",
        "9. How would you monitor this enrichment process in production?\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "**Immediate:** Load your enriched data into SQL Server\n",
        "**Tomorrow:** Rebuild this pipeline using Azure Data Factory\n",
        "**This Week:** Add error handling, monitoring, and production patterns\n",
        "**Back at Work:** Identify enrichment opportunities for your organisation's data"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}